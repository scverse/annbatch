{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Quickstart `annbatch`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook will walk you through the following steps:\n",
                "1. How to convert an existing collection of `anndata` files into a shuffled, zarr-based, collection of `anndata` datasets\n",
                "2. How to load the converted collection using `annbatch`\n",
                "3. Extend an existing collection with new `anndata` datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [],
            "source": [
                "# !pip install annbatch[zarrs, torch]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--2025-10-09 09:43:19--  https://datasets.cellxgene.cziscience.com/866d7d5e-436b-4dbd-b7c1-7696487d452e.h5ad\n",
                        "Resolving datasets.cellxgene.cziscience.com (datasets.cellxgene.cziscience.com)... 18.64.79.73, 18.64.79.80, 18.64.79.109, ...\n",
                        "Connecting to datasets.cellxgene.cziscience.com (datasets.cellxgene.cziscience.com)|18.64.79.73|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 773247972 (737M) [binary/octet-stream]\n",
                        "Saving to: ‘866d7d5e-436b-4dbd-b7c1-7696487d452e.h5ad’\n",
                        "\n",
                        "866d7d5e-436b-4dbd- 100%[===================>] 737.43M   398MB/s    in 1.9s    \n",
                        "\n",
                        "2025-10-09 09:43:21 (398 MB/s) - ‘866d7d5e-436b-4dbd-b7c1-7696487d452e.h5ad’ saved [773247972/773247972]\n",
                        "\n",
                        "--2025-10-09 09:43:22--  https://datasets.cellxgene.cziscience.com/f81463b8-4986-4904-a0ea-20ff02cbb317.h5ad\n",
                        "Resolving datasets.cellxgene.cziscience.com (datasets.cellxgene.cziscience.com)... 18.64.79.73, 18.64.79.80, 18.64.79.72, ...\n",
                        "Connecting to datasets.cellxgene.cziscience.com (datasets.cellxgene.cziscience.com)|18.64.79.73|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 1631759823 (1.5G) [binary/octet-stream]\n",
                        "Saving to: ‘f81463b8-4986-4904-a0ea-20ff02cbb317.h5ad’\n",
                        "\n",
                        "f81463b8-4986-4904- 100%[===================>]   1.52G   425MB/s    in 3.9s    \n",
                        "\n",
                        "2025-10-09 09:43:26 (403 MB/s) - ‘f81463b8-4986-4904-a0ea-20ff02cbb317.h5ad’ saved [1631759823/1631759823]\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Download two example datasets from CELLxGENE\n",
                "!wget https://datasets.cellxgene.cziscience.com/866d7d5e-436b-4dbd-b7c1-7696487d452e.h5ad\n",
                "!wget https://datasets.cellxgene.cziscience.com/f81463b8-4986-4904-a0ea-20ff02cbb317.h5ad"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**IMPORTANT**: Configure zarrs\n",
                "\n",
                "This step is both required for converting existing `anndata` files into a performant, shuffled collection of datasets for mini batch loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<donfig.config_obj.ConfigSet at 0x7f203c0b6900>"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import zarr\n",
                "import zarrs  # noqa\n",
                "\n",
                "zarr.config.set({\"codec_pipeline.path\": \"zarrs.ZarrsCodecPipeline\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "\n",
                "# Suppress zarr vlen-utf8 codec warnings\n",
                "warnings.filterwarnings(\n",
                "    \"ignore\",\n",
                "    message=\"The codec `vlen-utf8` is currently not part in the Zarr format 3 specification.*\",\n",
                "    category=UserWarning,\n",
                "    module=\"zarr.codecs.vlen_utf8\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Converting existing `anndata` files into a shuffled collection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The conversion code will take care of the following things:\n",
                "* Align (outer join) the gene spaces across all datasets listed in `adata_paths`\n",
                "  * The gene spaces are outer-joined based on the gene names provided in the `var_names` field of the individual `AnnData` objects.\n",
                "  * If you want to subset to specific gene space, you can provide a list of gene names via the `var_subset` parameter.\n",
                "* Shuffle the cells across all datasets (this works on larger than memory datasets as well).\n",
                "  * This is important for block-wise shuffling during data loading.\n",
                "* Shuffle the input files across multiple output datasets:\n",
                "  * The size of each individual output dataset can be controlled via the `n_obs_per_dataset` parameter.\n",
                "  * We recommend to choose a dataset size that comfortably fits into system memory.\n",
                "\n",
                "\n",
                "You can apply custom data transformations to each input h5ad file by supplying a `load_adata` function to `PreShuffledCollection.create_anndata_collection`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [],
            "source": [
                "import anndata as ad\n",
                "from annbatch import PreShuffledCollection\n",
                "\n",
                "\n",
                "# For CELLxGENE data, the raw counts can either be found under .raw.X or under .X (if .raw is not supplied).\n",
                "# To have a store that only contains raw counts, we can write the following load_adata function\n",
                "def read_lazy_x_and_obs_only(path) -> ad.AnnData:\n",
                "    \"\"\"Custom load function to only load raw counts from CxG data.\"\"\"\n",
                "    # IMPORTANT: Large data should always be loaded lazily to reduce the memory footprint\n",
                "    adata_ = ad.experimental.read_lazy(path)\n",
                "    if adata_.raw is not None:\n",
                "        x = adata_.raw.X\n",
                "        var = adata_.raw.var\n",
                "    else:\n",
                "        x = adata_.X\n",
                "        var = adata_.var\n",
                "\n",
                "    return ad.AnnData(\n",
                "        X=x,\n",
                "        obs=adata_.obs.to_memory(),\n",
                "        var=var.to_memory(),\n",
                "    )\n",
                "\n",
                "\n",
                "collection = PreShuffledCollection(zarr.open(\"annbatch_collection\"))\n",
                "collection.create_anndata_collection(\n",
                "    # List all the h5ad files you want to include in the collection\n",
                "    adata_paths=[\"866d7d5e-436b-4dbd-b7c1-7696487d452e.h5ad\", \"f81463b8-4986-4904-a0ea-20ff02cbb317.h5ad\"],\n",
                "    # Path to store the output collection\n",
                "    shuffle=True,  # Whether to pre-shuffle the cells of the collection\n",
                "    n_obs_per_dataset=2_097_152,  # Number of cells per dataset shard\n",
                "    var_subset=None,  # Optionally subset the collection to a specific gene space\n",
                "    load_adata=read_lazy_x_and_obs_only,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data loading example"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "COLLECTION_PATH = Path(\"annbatch_collection/\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<annbatch.sparse.Loader at 0x7f1ed87a88c0>"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import anndata as ad\n",
                "\n",
                "from annbatch import Loader\n",
                "\n",
                "ds = Loader(\n",
                "    batch_size=4096,  # Total number of obs per yielded batch\n",
                "    chunk_size=256,  # Number of obs to load from disk contiguously - default settings should work well\n",
                "    preload_nchunks=32,  # Number of chunks to preload + shuffle - default settings should work well\n",
                "    preload_to_gpu=False,\n",
                "    # If True, preloaded chunks are moved to GPU memory via `cupy`, which can put more pressure on GPU memory but will accelerate loading ~20%\n",
                "    to_torch=True,\n",
                ")\n",
                "\n",
                "# Add dataset that should be used for training\n",
                "ds.add_anndatas(\n",
                "    [\n",
                "        ad.AnnData(\n",
                "            X=ad.io.sparse_dataset(zarr.open(p)[\"X\"]),\n",
                "            obs=ad.io.read_elem(zarr.open(p)[\"obs\"]),\n",
                "        )\n",
                "        for p in COLLECTION_PATH.glob(\"*.zarr\")\n",
                "    ],\n",
                "    obs_keys=\"cell_type\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**IMPORTANT:**\n",
                "* The `Loader` yields batches of sparse tensors.\n",
                "* The conversion to dense tensors should be done on the GPU, as shown in the example below.\n",
                "  * First call `.cuda()` and then `.to_dense()`\n",
                "  * E.g. `x = x.cuda().to_dense()`\n",
                "  * This is significantly faster than doing the dense conversion on the CPU.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/171792 [00:00<?, ?it/s]/mnt/volume/arrayloaders/src/annbatch/utils.py:307: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
                        "  tensor = torch.sparse_csr_tensor(\n",
                        "  0%|          | 42/171792 [00:04<5:33:36,  8.58it/s]\n"
                    ]
                }
            ],
            "source": [
                "# Iterate over dataloader\n",
                "import tqdm\n",
                "\n",
                "for batch in tqdm.tqdm(ds):\n",
                "    x, obs = batch\n",
                "    # Important: Convert to dense on GPU\n",
                "    x = x.cuda().to_dense()\n",
                "    # Feed data into your model\n",
                "    ..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optional: Extend an existing collection with a new dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You might want to extend an existing pre-shuffled collection with a new dataset.\n",
                "This can be done using the `add_to_collection` function.\n",
                "\n",
                "This function will take care of shuffling the new dataset into the existing collection without having to re-shuffle the entire collection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide-output"
                ]
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/1 [00:00<?, ?it/s]/home/ubuntu/home_drive/volume/arrayloaders/venv/lib/python3.12/site-packages/anndata/_core/anndata.py:1791: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
                        "  utils.warn_names_duplicates(\"obs\")\n",
                        "/home/ubuntu/home_drive/volume/arrayloaders/venv/lib/python3.12/site-packages/anndata/_core/anndata.py:1791: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
                        "  utils.warn_names_duplicates(\"obs\")\n",
                        "/home/ubuntu/home_drive/volume/arrayloaders/venv/lib/python3.12/site-packages/anndata/_core/anndata.py:1791: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
                        "  utils.warn_names_duplicates(\"obs\")\n",
                        "/home/ubuntu/home_drive/volume/arrayloaders/venv/lib/python3.12/site-packages/zarr/api/asynchronous.py:244: ZarrUserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
                        "  warnings.warn(\n",
                        "100%|██████████| 1/1 [00:30<00:00, 30.76s/it]\n"
                    ]
                }
            ],
            "source": [
                "def read_x_and_obs_only(path) -> ad.AnnData:\n",
                "    \"\"\"Custom load function to only load raw counts from CxG data.\"\"\"\n",
                "    # As it's only a small dataset, we can load the full dataset into memory to speed up computations\n",
                "    adata_ = ad.read_h5ad(path)  # Replace with ad.experimental.read_lazy if data does not fit into memory anymore\n",
                "    if adata_.raw is not None:\n",
                "        x = adata_.raw.X\n",
                "        var = adata_.raw.var\n",
                "    else:\n",
                "        x = adata_.X\n",
                "        var = adata_.var\n",
                "\n",
                "    return ad.AnnData(X=x, obs=adata_.obs, var=var)\n",
                "\n",
                "\n",
                "collection.add_to_collection(\n",
                "    adata_paths=[\n",
                "        \"866d7d5e-436b-4dbd-b7c1-7696487d452e.h5ad\",\n",
                "    ],\n",
                "    load_adata=read_x_and_obs_only,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
